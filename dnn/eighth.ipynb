{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abf2444",
   "metadata": {},
   "source": [
    " # Scikit-Learn ve  Keras ile Ensemble Modelleme\n",
    " \n",
    " ## Öznitelik Önemini Değerlendirme (Evaluating Feature Importance)\n",
    " \n",
    "Feature Importance, bize her bir özelliğin bir sinir ağının veya başka bir modelin tahmini için ne kadar önemli olduğu hakkında bilgi verir. Sinir ağları için özelliğin önemini değerlendirmenin birçok farklı yolu vardır. Sinir ağları için aşağıdaki yöntemler mevcuttur.</br>\n",
    "\n",
    "<li>Connection Weights Algorithm</li>\n",
    "<li>Partial Derivatives</li>\n",
    "<li>Input Perturbation</li>\n",
    "<li>Sensitivity Analysis</li>\n",
    "<li>Forward Stepwise Addition</li>\n",
    "<li>Improved Stepwise Selection 1</li>\n",
    "<li>Backward Stepwise Elimination</li>\n",
    "<li>Improved Stepwise Selection</li>\n",
    "\n",
    "Burada, Input Perturbation özellik sıralama algoritması anlatılacaktır. Bu algoritma, herhangi bir regresyon veya sınıflandırma ağıyla çalışmaktadır.Bu algoritma  Leo Breiman tarafından  rastgele ormanlar hakkındaki makalesinde sunulmuştur. Bu algoritmayı rastgele ormanlarla birlikte sunmasına rağmen, modelden bağımsızdır ve herhangi bir denetimli öğrenme modeli için uygundur. Input Perturbation algoritması olarak bilinen bu algoritma, bir veri kümesinden ayrı ayrı karıştırılan girdilerin her biri ile eğitimli bir modelin doğruluğunu değerlendirerek çalışır. </br>\n",
    "\n",
    "Bu algoritma, bir sınıflandırma problemini değerlendirmek için log loss ve regresyon için RMSE'yi kullanmaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e4d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "def pertubration_rank(model, X, y, names, regression):\n",
    "    errors = []\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        hold = np.array(X[:, i])\n",
    "        np.random.shuffle(X[:, i])\n",
    "        \n",
    "        if regression:\n",
    "            pred = model.predict(X)\n",
    "            errors.append(mean_squared_error(y, pred))\n",
    "        else:\n",
    "            pred = model.predict_proba(X)\n",
    "            errors.append(log_loss(y, pred))\n",
    "        \n",
    "        X[:, i] = hold\n",
    "    \n",
    "    max_error = np.max(errors)\n",
    "    importance = [e / max_error for e in errors]\n",
    "\n",
    "    data = {'name': names, 'error': errors, 'importance': importance}\n",
    "    result = pd.DataFrame(data, columns=['name', 'error', 'importance'])\n",
    "    result.sort_values(by=['importance'], ascending=False, inplace=True)\n",
    "    result.reset_index(inplace=True, drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408bc303",
   "metadata": {},
   "source": [
    "# Classification and Input Perturbation Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6b45a5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 - 0s - loss: 2.0061\n",
      "Epoch 2/100\n",
      "4/4 - 0s - loss: 1.5384\n",
      "Epoch 3/100\n",
      "4/4 - 0s - loss: 1.3198\n",
      "Epoch 4/100\n",
      "4/4 - 0s - loss: 1.1909\n",
      "Epoch 5/100\n",
      "4/4 - 0s - loss: 1.0542\n",
      "Epoch 6/100\n",
      "4/4 - 0s - loss: 0.9674\n",
      "Epoch 7/100\n",
      "4/4 - 0s - loss: 0.9075\n",
      "Epoch 8/100\n",
      "4/4 - 0s - loss: 0.8683\n",
      "Epoch 9/100\n",
      "4/4 - 0s - loss: 0.8331\n",
      "Epoch 10/100\n",
      "4/4 - 0s - loss: 0.8019\n",
      "Epoch 11/100\n",
      "4/4 - 0s - loss: 0.7713\n",
      "Epoch 12/100\n",
      "4/4 - 0s - loss: 0.7364\n",
      "Epoch 13/100\n",
      "4/4 - 0s - loss: 0.7083\n",
      "Epoch 14/100\n",
      "4/4 - 0s - loss: 0.6840\n",
      "Epoch 15/100\n",
      "4/4 - 0s - loss: 0.6642\n",
      "Epoch 16/100\n",
      "4/4 - 0s - loss: 0.6453\n",
      "Epoch 17/100\n",
      "4/4 - 0s - loss: 0.6276\n",
      "Epoch 18/100\n",
      "4/4 - 0s - loss: 0.6113\n",
      "Epoch 19/100\n",
      "4/4 - 0s - loss: 0.5965\n",
      "Epoch 20/100\n",
      "4/4 - 0s - loss: 0.5818\n",
      "Epoch 21/100\n",
      "4/4 - 0s - loss: 0.5684\n",
      "Epoch 22/100\n",
      "4/4 - 0s - loss: 0.5558\n",
      "Epoch 23/100\n",
      "4/4 - 0s - loss: 0.5437\n",
      "Epoch 24/100\n",
      "4/4 - 0s - loss: 0.5323\n",
      "Epoch 25/100\n",
      "4/4 - 0s - loss: 0.5216\n",
      "Epoch 26/100\n",
      "4/4 - 0s - loss: 0.5112\n",
      "Epoch 27/100\n",
      "4/4 - 0s - loss: 0.5026\n",
      "Epoch 28/100\n",
      "4/4 - 0s - loss: 0.4933\n",
      "Epoch 29/100\n",
      "4/4 - 0s - loss: 0.4842\n",
      "Epoch 30/100\n",
      "4/4 - 0s - loss: 0.4770\n",
      "Epoch 31/100\n",
      "4/4 - 0s - loss: 0.4683\n",
      "Epoch 32/100\n",
      "4/4 - 0s - loss: 0.4606\n",
      "Epoch 33/100\n",
      "4/4 - 0s - loss: 0.4533\n",
      "Epoch 34/100\n",
      "4/4 - 0s - loss: 0.4462\n",
      "Epoch 35/100\n",
      "4/4 - 0s - loss: 0.4391\n",
      "Epoch 36/100\n",
      "4/4 - 0s - loss: 0.4325\n",
      "Epoch 37/100\n",
      "4/4 - 0s - loss: 0.4265\n",
      "Epoch 38/100\n",
      "4/4 - 0s - loss: 0.4199\n",
      "Epoch 39/100\n",
      "4/4 - 0s - loss: 0.4134\n",
      "Epoch 40/100\n",
      "4/4 - 0s - loss: 0.4075\n",
      "Epoch 41/100\n",
      "4/4 - 0s - loss: 0.4025\n",
      "Epoch 42/100\n",
      "4/4 - 0s - loss: 0.3995\n",
      "Epoch 43/100\n",
      "4/4 - 0s - loss: 0.3906\n",
      "Epoch 44/100\n",
      "4/4 - 0s - loss: 0.3847\n",
      "Epoch 45/100\n",
      "4/4 - 0s - loss: 0.3789\n",
      "Epoch 46/100\n",
      "4/4 - 0s - loss: 0.3731\n",
      "Epoch 47/100\n",
      "4/4 - 0s - loss: 0.3674\n",
      "Epoch 48/100\n",
      "4/4 - 0s - loss: 0.3630\n",
      "Epoch 49/100\n",
      "4/4 - 0s - loss: 0.3570\n",
      "Epoch 50/100\n",
      "4/4 - 0s - loss: 0.3513\n",
      "Epoch 51/100\n",
      "4/4 - 0s - loss: 0.3468\n",
      "Epoch 52/100\n",
      "4/4 - 0s - loss: 0.3423\n",
      "Epoch 53/100\n",
      "4/4 - 0s - loss: 0.3367\n",
      "Epoch 54/100\n",
      "4/4 - 0s - loss: 0.3318\n",
      "Epoch 55/100\n",
      "4/4 - 0s - loss: 0.3259\n",
      "Epoch 56/100\n",
      "4/4 - 0s - loss: 0.3209\n",
      "Epoch 57/100\n",
      "4/4 - 0s - loss: 0.3166\n",
      "Epoch 58/100\n",
      "4/4 - 0s - loss: 0.3102\n",
      "Epoch 59/100\n",
      "4/4 - 0s - loss: 0.3055\n",
      "Epoch 60/100\n",
      "4/4 - 0s - loss: 0.3032\n",
      "Epoch 61/100\n",
      "4/4 - 0s - loss: 0.2956\n",
      "Epoch 62/100\n",
      "4/4 - 0s - loss: 0.2909\n",
      "Epoch 63/100\n",
      "4/4 - 0s - loss: 0.2865\n",
      "Epoch 64/100\n",
      "4/4 - 0s - loss: 0.2817\n",
      "Epoch 65/100\n",
      "4/4 - 0s - loss: 0.2786\n",
      "Epoch 66/100\n",
      "4/4 - 0s - loss: 0.2717\n",
      "Epoch 67/100\n",
      "4/4 - 0s - loss: 0.2689\n",
      "Epoch 68/100\n",
      "4/4 - 0s - loss: 0.2645\n",
      "Epoch 69/100\n",
      "4/4 - 0s - loss: 0.2592\n",
      "Epoch 70/100\n",
      "4/4 - 0s - loss: 0.2546\n",
      "Epoch 71/100\n",
      "4/4 - 0s - loss: 0.2492\n",
      "Epoch 72/100\n",
      "4/4 - 0s - loss: 0.2450\n",
      "Epoch 73/100\n",
      "4/4 - 0s - loss: 0.2405\n",
      "Epoch 74/100\n",
      "4/4 - 0s - loss: 0.2359\n",
      "Epoch 75/100\n",
      "4/4 - 0s - loss: 0.2321\n",
      "Epoch 76/100\n",
      "4/4 - 0s - loss: 0.2273\n",
      "Epoch 77/100\n",
      "4/4 - 0s - loss: 0.2227\n",
      "Epoch 78/100\n",
      "4/4 - 0s - loss: 0.2188\n",
      "Epoch 79/100\n",
      "4/4 - 0s - loss: 0.2168\n",
      "Epoch 80/100\n",
      "4/4 - 0s - loss: 0.2118\n",
      "Epoch 81/100\n",
      "4/4 - 0s - loss: 0.2090\n",
      "Epoch 82/100\n",
      "4/4 - 0s - loss: 0.2045\n",
      "Epoch 83/100\n",
      "4/4 - 0s - loss: 0.2008\n",
      "Epoch 84/100\n",
      "4/4 - 0s - loss: 0.1958\n",
      "Epoch 85/100\n",
      "4/4 - 0s - loss: 0.1913\n",
      "Epoch 86/100\n",
      "4/4 - 0s - loss: 0.1887\n",
      "Epoch 87/100\n",
      "4/4 - 0s - loss: 0.1848\n",
      "Epoch 88/100\n",
      "4/4 - 0s - loss: 0.1812\n",
      "Epoch 89/100\n",
      "4/4 - 0s - loss: 0.1775\n",
      "Epoch 90/100\n",
      "4/4 - 0s - loss: 0.1749\n",
      "Epoch 91/100\n",
      "4/4 - 0s - loss: 0.1711\n",
      "Epoch 92/100\n",
      "4/4 - 0s - loss: 0.1697\n",
      "Epoch 93/100\n",
      "4/4 - 0s - loss: 0.1665\n",
      "Epoch 94/100\n",
      "4/4 - 0s - loss: 0.1627\n",
      "Epoch 95/100\n",
      "4/4 - 0s - loss: 0.1602\n",
      "Epoch 96/100\n",
      "4/4 - 0s - loss: 0.1574\n",
      "Epoch 97/100\n",
      "4/4 - 0s - loss: 0.1548\n",
      "Epoch 98/100\n",
      "4/4 - 0s - loss: 0.1545\n",
      "Epoch 99/100\n",
      "4/4 - 0s - loss: 0.1531\n",
      "Epoch 100/100\n",
      "4/4 - 0s - loss: 0.1487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5f85052b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://data.heatonresearch.com/data/t81-558/iris.csv', \n",
    "                na_values=['NA', '?'])\n",
    "\n",
    "X = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
    "dummies = pd.get_dummies(df['species'])\n",
    "species = dummies.columns\n",
    "y = dummies.values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train, y_train, verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c007424f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "predict_classes = np.argmax(pred, axis=1)\n",
    "expected_classes = np.argmax(y_test, axis=1)\n",
    "acc_score = accuracy_score(expected_classes, predict_classes)\n",
    "acc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5fc4685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-c17d7c20dee9>:17: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>petal_l</td>\n",
       "      <td>2.076535</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>petal_w</td>\n",
       "      <td>0.764929</td>\n",
       "      <td>0.368368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sepal_l</td>\n",
       "      <td>0.187102</td>\n",
       "      <td>0.090103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sepal_w</td>\n",
       "      <td>0.164346</td>\n",
       "      <td>0.079144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name     error  importance\n",
       "0  petal_l  2.076535    1.000000\n",
       "1  petal_w  0.764929    0.368368\n",
       "2  sepal_l  0.187102    0.090103\n",
       "3  sepal_w  0.164346    0.079144"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(df.columns)\n",
    "names.remove('species')\n",
    "rank = pertubration_rank(model, X_test, y_test, names, False)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf6890",
   "metadata": {},
   "source": [
    "# Regression and Input Perturbation Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd46fab9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 - 0s - loss: 158333.4375\n",
      "Epoch 2/100\n",
      "10/10 - 0s - loss: 36110.2852\n",
      "Epoch 3/100\n",
      "10/10 - 0s - loss: 2571.4780\n",
      "Epoch 4/100\n",
      "10/10 - 0s - loss: 2961.1277\n",
      "Epoch 5/100\n",
      "10/10 - 0s - loss: 2609.2681\n",
      "Epoch 6/100\n",
      "10/10 - 0s - loss: 1147.0244\n",
      "Epoch 7/100\n",
      "10/10 - 0s - loss: 976.5759\n",
      "Epoch 8/100\n",
      "10/10 - 0s - loss: 1012.1773\n",
      "Epoch 9/100\n",
      "10/10 - 0s - loss: 939.4510\n",
      "Epoch 10/100\n",
      "10/10 - 0s - loss: 922.3546\n",
      "Epoch 11/100\n",
      "10/10 - 0s - loss: 914.5435\n",
      "Epoch 12/100\n",
      "10/10 - 0s - loss: 903.9374\n",
      "Epoch 13/100\n",
      "10/10 - 0s - loss: 894.3073\n",
      "Epoch 14/100\n",
      "10/10 - 0s - loss: 885.1788\n",
      "Epoch 15/100\n",
      "10/10 - 0s - loss: 878.3129\n",
      "Epoch 16/100\n",
      "10/10 - 0s - loss: 869.5519\n",
      "Epoch 17/100\n",
      "10/10 - 0s - loss: 857.3226\n",
      "Epoch 18/100\n",
      "10/10 - 0s - loss: 848.4277\n",
      "Epoch 19/100\n",
      "10/10 - 0s - loss: 837.5118\n",
      "Epoch 20/100\n",
      "10/10 - 0s - loss: 827.2177\n",
      "Epoch 21/100\n",
      "10/10 - 0s - loss: 819.4198\n",
      "Epoch 22/100\n",
      "10/10 - 0s - loss: 808.4346\n",
      "Epoch 23/100\n",
      "10/10 - 0s - loss: 798.1693\n",
      "Epoch 24/100\n",
      "10/10 - 0s - loss: 786.8827\n",
      "Epoch 25/100\n",
      "10/10 - 0s - loss: 776.9139\n",
      "Epoch 26/100\n",
      "10/10 - 0s - loss: 767.6911\n",
      "Epoch 27/100\n",
      "10/10 - 0s - loss: 755.6787\n",
      "Epoch 28/100\n",
      "10/10 - 0s - loss: 744.8003\n",
      "Epoch 29/100\n",
      "10/10 - 0s - loss: 743.7242\n",
      "Epoch 30/100\n",
      "10/10 - 0s - loss: 724.8375\n",
      "Epoch 31/100\n",
      "10/10 - 0s - loss: 713.9089\n",
      "Epoch 32/100\n",
      "10/10 - 0s - loss: 703.0914\n",
      "Epoch 33/100\n",
      "10/10 - 0s - loss: 692.4356\n",
      "Epoch 34/100\n",
      "10/10 - 0s - loss: 680.6689\n",
      "Epoch 35/100\n",
      "10/10 - 0s - loss: 671.0513\n",
      "Epoch 36/100\n",
      "10/10 - 0s - loss: 660.9953\n",
      "Epoch 37/100\n",
      "10/10 - 0s - loss: 653.2566\n",
      "Epoch 38/100\n",
      "10/10 - 0s - loss: 637.6747\n",
      "Epoch 39/100\n",
      "10/10 - 0s - loss: 628.2769\n",
      "Epoch 40/100\n",
      "10/10 - 0s - loss: 617.3808\n",
      "Epoch 41/100\n",
      "10/10 - 0s - loss: 610.3919\n",
      "Epoch 42/100\n",
      "10/10 - 0s - loss: 599.2336\n",
      "Epoch 43/100\n",
      "10/10 - 0s - loss: 589.1202\n",
      "Epoch 44/100\n",
      "10/10 - 0s - loss: 576.7305\n",
      "Epoch 45/100\n",
      "10/10 - 0s - loss: 568.8988\n",
      "Epoch 46/100\n",
      "10/10 - 0s - loss: 555.7560\n",
      "Epoch 47/100\n",
      "10/10 - 0s - loss: 551.8015\n",
      "Epoch 48/100\n",
      "10/10 - 0s - loss: 537.6070\n",
      "Epoch 49/100\n",
      "10/10 - 0s - loss: 527.8979\n",
      "Epoch 50/100\n",
      "10/10 - 0s - loss: 519.5652\n",
      "Epoch 51/100\n",
      "10/10 - 0s - loss: 507.8203\n",
      "Epoch 52/100\n",
      "10/10 - 0s - loss: 499.7944\n",
      "Epoch 53/100\n",
      "10/10 - 0s - loss: 490.0560\n",
      "Epoch 54/100\n",
      "10/10 - 0s - loss: 479.5498\n",
      "Epoch 55/100\n",
      "10/10 - 0s - loss: 471.9905\n",
      "Epoch 56/100\n",
      "10/10 - 0s - loss: 461.9854\n",
      "Epoch 57/100\n",
      "10/10 - 0s - loss: 452.9034\n",
      "Epoch 58/100\n",
      "10/10 - 0s - loss: 444.1691\n",
      "Epoch 59/100\n",
      "10/10 - 0s - loss: 436.6926\n",
      "Epoch 60/100\n",
      "10/10 - 0s - loss: 430.0872\n",
      "Epoch 61/100\n",
      "10/10 - 0s - loss: 423.3643\n",
      "Epoch 62/100\n",
      "10/10 - 0s - loss: 411.2040\n",
      "Epoch 63/100\n",
      "10/10 - 0s - loss: 404.8961\n",
      "Epoch 64/100\n",
      "10/10 - 0s - loss: 395.2644\n",
      "Epoch 65/100\n",
      "10/10 - 0s - loss: 388.7475\n",
      "Epoch 66/100\n",
      "10/10 - 0s - loss: 384.1960\n",
      "Epoch 67/100\n",
      "10/10 - 0s - loss: 372.0062\n",
      "Epoch 68/100\n",
      "10/10 - 0s - loss: 365.4352\n",
      "Epoch 69/100\n",
      "10/10 - 0s - loss: 355.1031\n",
      "Epoch 70/100\n",
      "10/10 - 0s - loss: 351.4371\n",
      "Epoch 71/100\n",
      "10/10 - 0s - loss: 339.5164\n",
      "Epoch 72/100\n",
      "10/10 - 0s - loss: 334.2998\n",
      "Epoch 73/100\n",
      "10/10 - 0s - loss: 325.5347\n",
      "Epoch 74/100\n",
      "10/10 - 0s - loss: 319.2354\n",
      "Epoch 75/100\n",
      "10/10 - 0s - loss: 311.8575\n",
      "Epoch 76/100\n",
      "10/10 - 0s - loss: 305.7526\n",
      "Epoch 77/100\n",
      "10/10 - 0s - loss: 298.5181\n",
      "Epoch 78/100\n",
      "10/10 - 0s - loss: 292.3569\n",
      "Epoch 79/100\n",
      "10/10 - 0s - loss: 286.1064\n",
      "Epoch 80/100\n",
      "10/10 - 0s - loss: 280.2179\n",
      "Epoch 81/100\n",
      "10/10 - 0s - loss: 273.6550\n",
      "Epoch 82/100\n",
      "10/10 - 0s - loss: 267.2669\n",
      "Epoch 83/100\n",
      "10/10 - 0s - loss: 261.9168\n",
      "Epoch 84/100\n",
      "10/10 - 0s - loss: 254.9390\n",
      "Epoch 85/100\n",
      "10/10 - 0s - loss: 250.0255\n",
      "Epoch 86/100\n",
      "10/10 - 0s - loss: 244.0302\n",
      "Epoch 87/100\n",
      "10/10 - 0s - loss: 239.4489\n",
      "Epoch 88/100\n",
      "10/10 - 0s - loss: 233.4313\n",
      "Epoch 89/100\n",
      "10/10 - 0s - loss: 229.2857\n",
      "Epoch 90/100\n",
      "10/10 - 0s - loss: 224.1042\n",
      "Epoch 91/100\n",
      "10/10 - 0s - loss: 217.5365\n",
      "Epoch 92/100\n",
      "10/10 - 0s - loss: 214.5557\n",
      "Epoch 93/100\n",
      "10/10 - 0s - loss: 208.3743\n",
      "Epoch 94/100\n",
      "10/10 - 0s - loss: 204.8385\n",
      "Epoch 95/100\n",
      "10/10 - 0s - loss: 200.5665\n",
      "Epoch 96/100\n",
      "10/10 - 0s - loss: 194.4728\n",
      "Epoch 97/100\n",
      "10/10 - 0s - loss: 190.8616\n",
      "Epoch 98/100\n",
      "10/10 - 0s - loss: 185.3742\n",
      "Epoch 99/100\n",
      "10/10 - 0s - loss: 181.3960\n",
      "Epoch 100/100\n",
      "10/10 - 0s - loss: 177.4355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5e012e1d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('https://data.heatonresearch.com/data/t81-558/auto-mpg.csv',                 \n",
    "                na_values=['NA', '?'])\n",
    "\n",
    "\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "X = df[['cylinders','displacement','horsepower','weight',\n",
    "        'acceleration','year','origin']].values\n",
    "y = df['mpg'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, verbose=2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8660043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skater.core.explanations import Interpretation\n",
    "interpreter = Interpretation()\n",
    "interpreter.load_data(X_test, feature_names=['cylinders','displacement','horsepower','weight',\n",
    "        'acceleration','year','origin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081e026f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "WARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "[1/7] features ██------------------ Time elapsed: 0 secondsWARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "[2/7] features █████--------------- Time elapsed: 0 secondsWARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "[3/7] features ████████------------ Time elapsed: 0 secondsWARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "[4/7] features ███████████--------- Time elapsed: 0 secondsWARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "[5/7] features ██████████████------ Time elapsed: 0 secondsWARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "[6/7] features █████████████████--- Time elapsed: 0 secondsWARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "[7/7] features ████████████████████ Time elapsed: 0 secondsWARNING:tensorflow:Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 432x288 with 1 Axes>, <AxesSubplot:>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skater.model import InMemoryModel\n",
    "pyint_model = InMemoryModel(model.predict_proba, examples=X_test)\n",
    "interpreter.feature_importance.plot_feature_importance(pyint_model, ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64f1509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>169.880932</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>origin</td>\n",
       "      <td>167.724839</td>\n",
       "      <td>0.987308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year</td>\n",
       "      <td>164.187733</td>\n",
       "      <td>0.966487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>160.176224</td>\n",
       "      <td>0.942873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>displacement</td>\n",
       "      <td>159.581775</td>\n",
       "      <td>0.939374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>horsepower</td>\n",
       "      <td>140.314277</td>\n",
       "      <td>0.825957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weight</td>\n",
       "      <td>113.418618</td>\n",
       "      <td>0.667636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name       error  importance\n",
       "0  acceleration  169.880932    1.000000\n",
       "1        origin  167.724839    0.987308\n",
       "2          year  164.187733    0.966487\n",
       "3     cylinders  160.176224    0.942873\n",
       "4  displacement  159.581775    0.939374\n",
       "5    horsepower  140.314277    0.825957\n",
       "6        weight  113.418618    0.667636"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(df.columns)\n",
    "names.remove('name')\n",
    "names.remove('mpg')\n",
    "rank = pertubration_rank(model, X_test, y_test, names, True)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d297d",
   "metadata": {},
   "source": [
    "# Kaggle Dataset Örneği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0820f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3751, 1777)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('train.csv', na_values=['NA', '?'])\n",
    "df_test = pd.read_csv('test.csv', na_values=['NA', '?'])\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "693bab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c2023a9e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_columns = df_train.columns.drop('Activity')\n",
    "X = df_train[X_columns].values\n",
    "y = df_train['Activity'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          callbacks=[monitor],verbose=0, epochs=1000)model.compile(loss='binary_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "533ac0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss =  0.5641294002190853\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test).flatten()\n",
    "pred = np.clip(pred, a_min=1e-6, a_max=(1-1e-6))\n",
    "print('log loss = ', log_loss(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb8b2c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7549933422103862"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pred > 0.5\n",
    "score = accuracy_score(y_test, pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40ca4f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99343234, 0.97884357, 0.38377544, ..., 0.9187938 , 0.8782425 ,\n",
       "       0.36218733], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_submit = df_test[X_columns].values\n",
    "pred_submit = model.predict(X_submit).flatten()\n",
    "pred_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b89a4f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D27</td>\n",
       "      <td>0.628330</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1402</td>\n",
       "      <td>0.572884</td>\n",
       "      <td>0.911757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D51</td>\n",
       "      <td>0.571632</td>\n",
       "      <td>0.909764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1188</td>\n",
       "      <td>0.571098</td>\n",
       "      <td>0.908914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D1049</td>\n",
       "      <td>0.571067</td>\n",
       "      <td>0.908864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>D1286</td>\n",
       "      <td>0.560469</td>\n",
       "      <td>0.891997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>D1337</td>\n",
       "      <td>0.560216</td>\n",
       "      <td>0.891595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>D1390</td>\n",
       "      <td>0.559554</td>\n",
       "      <td>0.890541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>D956</td>\n",
       "      <td>0.558911</td>\n",
       "      <td>0.889518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>D997</td>\n",
       "      <td>0.558859</td>\n",
       "      <td>0.889435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1776 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name     error  importance\n",
       "0       D27  0.628330    1.000000\n",
       "1     D1402  0.572884    0.911757\n",
       "2       D51  0.571632    0.909764\n",
       "3     D1188  0.571098    0.908914\n",
       "4     D1049  0.571067    0.908864\n",
       "...     ...       ...         ...\n",
       "1771  D1286  0.560469    0.891997\n",
       "1772  D1337  0.560216    0.891595\n",
       "1773  D1390  0.559554    0.890541\n",
       "1774   D956  0.558911    0.889518\n",
       "1775   D997  0.558859    0.889435\n",
       "\n",
       "[1776 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(df_train.columns)\n",
    "names.remove('Activity')\n",
    "rank = pertubration_rank(model, X_test, y_test, names, False)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2bd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7eabed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
